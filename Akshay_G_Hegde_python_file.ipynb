import pandas as pd

Above step innvolves Ingesting the data into python.
# Get the FILE_ID from your Google Drive shareable link.
# For example, if your shareable link is 'https://drive.google.com/file/d/THIS_IS_YOUR_FILE_ID/view?usp=drive_link'
file_id = '14OW84qDiVVNw97gexiB9wVNxJCjr5Iye'
url = f'https://drive.google.com/uc?export=download&id={file_id}'

#The below steps are normalizing the data into multiple sub-tables
df = pd.read_json(url)
print(df.head())

#below steps innvolve loading the normalized data into mysql
valuation_df = pd.DataFrame(df['Valuation'])
HOA_df = pd.DataFrame(df['HOA'])


valuation_df.head(5)

Rehab_df = pd.DataFrame(df['Rehab'])
Rehab_df.head(5)

#below steps innvolve loading the normalized data into mysql

pip install mysql-connector-python

import mysql.connector

try:
        mydb = mysql.connector.connect(
            # The following line was causing a SyntaxError.
            # Function arguments use '=' not ':', and 'ROOT_PASSWORD' is not a valid parameter.
            # If you intended to specify the host, use host='your_mysql_host_or_ip'.
            user="db_user",
            password="6equj5_db_user",
            database="home_db"  # Optional: specify a database to connect to directly
        )
        print("Connection to MySQL established successfully!")

except mysql.connector.Error as err:
        print(f"Error connecting to MySQL: {err}")


pip install pandas sqlalchemy pymysql


from sqlalchemy import create_engine

db_connection = create_engine(my_db)

table_name1 = 'properties_data'
table_name2 = 'HOA'
Table_name3='valuation'
table_name4='rehab'

    df.to_sql(name=table_name1, con=db_connection, if_exists='replace', index=False)
    valuation_df.to_sql(name=table_name2, con=db_connection, if_exists='replace', index=False)
    HOA_df.to_sql(name=table_name3, con=db_connection, if_exists='replace', index=False)
    Rehab_df.to_sql(name=table_name4, con=db_connection, if_exists='replace', index=False)
